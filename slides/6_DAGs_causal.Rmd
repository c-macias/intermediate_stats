---
title: "DAGs and causal inference"
author: "Frank Edwards"
date: "2/25/2020"
output: binb::metropolis
---

```{r setup, include=FALSE}
library(rethinking)
library(dagitty)
library(gridExtra)
library(tidyverse)
set.seed(1)

knitr::opts_chunk$set(tidy = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

## Ways to obtain biased regression estimates (for causal inference)

1. Omitted variable bias (spurious, masked associations)
2. Multicollinearity
3. **Post-treatment bias**

## The experiment

In an experimental setting where we want to know the effect of a *treatment* on an outcome, we should not condition on variables whose effect would occur *after* exposure to treatment. \pause

- **Q:** How much do plants grow under different anti-fungal soil treatments?
- **Data:** Initial heights (h0), assignment to treatment (treatment), presence of fungus (fungus), height post-treatment (h1)

Simulation code for this exercise included in the .Rmd file

## The data

```{r size = "tiny"}
N<-100
d<-data.frame(h0=rnorm(N, 10, 2), # generate initial height
              treatment = rep(c(0,1), each = N/2)) # random assignment to treatment

d<-d %>% 
  mutate(fungus = rbinom(N, size = 1, prob = 0.5 - treatment * 0.4), # p(fungus) is lower for treated
         h1 = h0 + rnorm(N, 5-3 * fungus, 1))

summary(d)
```

## The model

We can model the effect of treatment on the height of a plant from time 0 to time 1 as

\[h_{1i} \sim \textrm{Normal}(\mu_i, \sigma) \]
\[\mu_i = h_{0i} \times p\]
\[p = \alpha + \beta_T T_i \]
\[\alpha \sim \textrm{Log-Normal}(0, 0.25)\]
\[\beta_T \sim \textrm{Normal}(0, 0.5)\]
\[\sigma \sim \textrm{Exponential}(1)\]

Note that we are modeling height by modeling proportional growth relative to initial height $h_0$ with the variable $p$

## Refresher on Log-Normal PDFs

- Log-Normal variables are always positive. If x is a Normal random variable, then $e^x$ is a log-normal random variable.

```{r echo = F, fig.height = 4}
ggplot(data.frame(x = seq(0, 5, length.out=100)), aes(x)) +
  stat_function(fun = dlnorm) + 
  ggtitle("Log-Normal(0, 1)")
```

## The causal model

Plant height at time 1 is influenced by:

1. Height at time 0
2. Fungus

Fungus is caused by:

1. Treatment

```{r echo = F, fig.height = 2, fig.width=4}
library(dagitty)
plant_dag <- dagitty( "dag {
  H_0 -> H_1
  F -> H_1
  T -> F
  }")
coordinates( plant_dag ) <- list( x=c(H_0=0,T=2,F=1.5,H_1=1) ,
                                  y=c(H_0=0,T=0,F=0,H_1=0) )
drawdag(plant_dag)

```

## Building the model

```{r}
fungus_0<-quap(alist(
  h1 ~ dnorm(mu, sigma),
  mu<- h0 * p,
  p<- a + bt * treatment,
  a ~ dlnorm(0, 0.25),
  bt ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)

summary(fungus_0)
```

## What happens if we condition on fungus?

\[h_{1i} \sim \textrm{Normal}(\mu_i, \sigma) \]
\[\mu_i = h_{0i} \times p\]
\[p = \alpha + \beta_T T_i + \beta_F F_i  \]
\[\alpha \sim \textrm{Log-Normal}(0, 0.25)\]
\[\beta_T \sim \textrm{Normal}(0, 0.5)\]
\[\beta_F \sim \textrm{Normal}(0, 0.5)\]
\[\sigma \sim \textrm{Exponential}(1)\]

## What happens if we condition on fungus?

```{r}
fungus_1<-quap(alist(
  h1 ~ dnorm(mu, sigma),
  mu<- h0 * p,
  p<- a + bt * treatment + bf * fungus,
  a ~ dlnorm(0, 0.25),
  bt ~ dnorm(0, 0.5),
  bf ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)

summary(fungus_1)
```

## What happens if we condition on fungus?

```{r echo = F, fig.height = 2, fig.width=4}
library(dagitty)
plant_dag <- dagitty( "dag {
  H_0 -> H_1
  F -> H_1
  T -> F
  }")
coordinates( plant_dag ) <- list( x=c(H_0=0,T=2,F=1.5,H_1=1) ,
                                  y=c(H_0=0,T=0,F=0,H_1=0) )
drawdag(plant_dag)

```

```{r fig.height = 3, echo = F}
plot(coeftab(fungus_0, fungus_1), pars = c("bt", "bf"))
```

## Post-treatment variables

- Treatment is independent of growth conditional on fungus. 
- Once fungus is in the model, treatment provides no additional information on growth, because T affects H by suppressing F.
- It is (generally) a bad idea to condition on measures that occurred *after* a focal treatment. Treatment could effect both the outcome and the post-treatment variable 

# Colliders

## Age, marriage and happiness

- Assume happiness is fixed at birth
- Happy people are more likely than sad people to marry
- Living longer makes you more likely to marry

## Our DAG

```{r echo = F, fig.height = 2, fig.width=3}
library(dagitty)
happy_dag <- dagitty( "dag {
  H -> M
  A -> M
  }")
coordinates(happy_dag) <- list(x=c(H=0,M=1,A=2),
                                  y=c(H=0,A=0,M=0))
drawdag(happy_dag)
```

Despite there being no causal relationship, conditioning on M opens a pathway between H and A. This is collider bias.

## Simulate some data

1. 20 people are born each year with uniformly distributed happiness values
2. Each person ages one year per year, happiness is unchanged
3. At 16, people can marry with probability proportional to happiness
4. No one divorces
5. At 65 they are removed

```{r}
d <- sim_happiness( seed=1977 , N_years=1000 )
```

## How does age relate to happiness?

\[H \sim N(\mu, \sigma)\]
\[\mu_i = \alpha_{Mi} + \beta_A A_i\]
\[\alpha_M \sim N(0,1)\]
\[\beta_A \sim N(0, 2)\]
\[\sigma \sim Exp(1)\]

We'll consider two models - one with marriage as a predictor, and one without

## Fit the models and compare $\beta_A$

```{r echo = F}
d2 <- d[ d$age>17 , ] 
# only adults 
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )

d2$mid <- d2$married + 1 
m6.9 <- quap(
  alist(
    happiness ~ dnorm( mu , sigma ), mu <- a[mid] + bA*A,
    a[mid] ~ dnorm( 0 , 1 ),
    bA ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)
  ) , data=d2 ) 
round(precis(m6.9,depth=2),2)

m6.10 <- quap( alist(
  happiness ~ dnorm( mu , sigma ), 
  mu <- a + bA*A,
  a ~ dnorm( 0 , 1 ),
  bA ~ dnorm( 0 , 2 ),
  sigma ~ dexp(1) ) , data=d2 )
round(precis(m6.10),2)
```

## Marriage induces a correlation between age and happiness

```{r echo =F}
ggplot(d, aes(x = age, y = happiness, alpha = married)) + 
  geom_point()
```

# Confounding 

## The classic example

An unobserved variable U confounds the relationship between education and wages

```{r echo = F, fig.height = 2, fig.width=3}
library(dagitty)
confound <- dagitty( "dag {
  U -> E
  U -> W
  E->W
  U[unobserved]
  }")
coordinates(confound) <- list(x=c(U=1,E=0,W=2),
                                  y=c(E=0,W=0,U=1))
drawdag(confound)
```

## The classic solution: randomization

- Randomizing education (experimentally or otherwise) breaks the relationship between E and U. 
- U still influences W, but because it no longer influences E, we can estimate the effect of E on W without bias.

```{r echo = F, fig.height = 2, fig.width=3}
confound <- dagitty( "dag {
  U -> W
  E->W
  U[unobserved]
  }")

coordinates(confound) <- list(x=c(U=1,E=0,W=2),
                                  y=c(E=0,W=0,U=1))
drawdag(confound)
```

## The statistical solution: conditioning

By adding U to the model, we block the flow of information on $E \leftarrow U \rightarrow W$, leaving only the path $E \rightarrow W$

```{r echo = F, fig.height = 2, fig.width=3}
confound <- dagitty( "dag {
  U -> E
  U -> W
  E->W
  U[unobserved]
  }")
coordinates(confound) <- list(x=c(U=1,E=0,W=2),
                                  y=c(E=0,W=0,U=1))
drawdag(confound)
```

## Searching for confounds, closing backdoors

- Confounds are spurious correlations between some outcome Y and some predictor X
- In a DAG, we should pay careful attention to causal paths that enter the "back" of predictor X and connect to outcome Y

With DAGs, we have two general goals:

1. Close all backdoor paths between X and Y
2. Leave focal causal paths between X and Y open

## The four basic DAGs: fork

- There is a backdoor path from X to Y, through Z
- X and Y are independent, conditional on Z

```{r echo = F, fig.height = 2, fig.width=3}
fork <- dagitty( "dag {
  Z -> X
  Z -> Y
  }")
coordinates(fork) <- list(x=c(X = 1, Z = 2, Y = 3),
                                  y=c(X = 0, Y = 0, Z = 1))
drawdag(fork)
```

## The four basic DAGs: pipe

- There is a causal path between X and Y through Z
- X and Y are independent, conditional on Z

```{r echo = F, fig.height = 2, fig.width=3}
fork <- dagitty( "dag {
  Z <- X
  Z -> Y
  }")
coordinates(fork) <- list(x=c(X = 1, Z = 2, Y = 3),
                                  y=c(X = 0, Y = 0, Z = 0))
drawdag(fork)
```

## The four basic DAGs: collider

- No causal path between X and Y
- Conditioning on Z opens a path between X and Y

```{r echo = F, fig.height = 2, fig.width=3}
collider <- dagitty( "dag {
  Z <- X
  Z <- Y
  }")
coordinates(collider) <- list(x=c(X = 1, Z = 2, Y = 3),
                                  y=c(X = 0, Y = 0, Z = 1))
drawdag(collider)
```

## The four basic DAGs: descendant

- No causal path between X and Y
- Conditioning on D opens a weaker path between X and Y than conditioning on Z (a collider)

```{r echo = F, fig.height = 2, fig.width=3}
descendent <- dagitty( "dag {
  Z <- X
  Z <- Y
  Z -> D
  }")
coordinates(descendent) <- list(x=c(X = 1, Z = 2, Y = 3, D = 2),
                                  y=c(X = 0, Y = 0, Z = 1, D = 0))
drawdag(descendent)
```

## General method for causal inference using DAGs

1. List all paths connecting X (focal cause) and Y (focal effect)
2. Classify each path is open or closed. A path is open unless it contains a collider
3. Identify backdoor paths (arrow entering X)
4. For any open backdoor paths, decide which variables to condition on to close it

## 

\centering{
\includegraphics{./vis/wafflehouse.jpeg}}

## Does Waffle House effect divorce rates

**S:** State in the South; **W:** Waffle houses per capita; **M:** Marriage rates; **A:** Median age at first marriage; **D:** Divorce rates

```{r echo = F, fig.height = 2, fig.width=3}
waffledag <- dagitty( "dag {
  A -> D
  A -> M -> D
  A <- S -> M
  S -> W -> D
  }")
coordinates(waffledag) <- list(x=c(S = 0, A = 0, M = 1, W = 2, D = 2),
                                  y=c(S = 0, W = 0 , A = 2, D = 2, M = 1))
drawdag(waffledag)
```

\pause

What causal relationships does this DAG assume?

## General method for causal inference using DAGs

1. List all paths connecting W (focal cause) and D (focal effect)
2. Classify each path is open or closed. A path is open unless it contains a collider
3. Identify backdoor paths (arrow entering W)
4. For any open backdoor paths, decide which variables to condition on to close it

## Checking our intuition

```{r size = "scriptsize"}
waffledag <- dagitty( "dag {
  A -> D
  A -> M -> D
  A <- S -> M
  S -> W -> D
  }")
adjustmentSets(waffledag, exposure = "W", outcome = "D")
```

## Evaluating the causal effect, assuming the prior DAG

```{r size = "tiny"}
data("WaffleDivorce")
d<-WaffleDivorce %>% 
  mutate(D = scale(Divorce),
         S = South + 1,
         A = scale(MedianAgeMarriage),
         W = scale(WaffleHouses / Population),
         M = scale(Marriage))

mWaffles<-quap(alist(
  D ~ dnorm(mu, sigma),
  mu <- a[S] + bW * W,
  a[S] ~ dnorm(0, 1),
  bW ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)

precis(mWaffles)
```

## Do we believe this DAG?

We can check whether the assumptions of the DAG hold:

```{r}
impliedConditionalIndependencies(waffledag)
```

These conditional independencies imply a series of regressions that we could estimate to test the validity of the DAG

## Summary

- DAGs are powerful tools that we can use to clarify our thinking and develop statistical models
- DAGs are assumptions with testable implications
- We've just scratched the surface! Check out http://www.dagitty.net/learn/ for more introductory materials
- Elwert and Winship (2014) provides a great review of DAGs and colliders: https://doi.org/10.1146/annurev-soc-071913-043455
- No homework this week, HW5 has been postponed: now due on 3/6
- More ggplot in lab on Friday (regular lecture time)