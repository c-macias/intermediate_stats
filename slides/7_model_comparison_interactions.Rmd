---
title: "Model comparison, interactions"
author: "Frank Edwards"
date: "3/6/2020"
output: binb::metropolis
---

```{r setup, include=FALSE}
library(rethinking)
library(dagitty)
library(gridExtra)
library(tidyverse)
set.seed(1)

knitr::opts_chunk$set(tidy = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

## How to assess a model

**If our goal is causal inference**

1. Construct causal theories (DAGs)
2. Determine testable implications of model (conditional indepencies)
3. Evaluate, critique, refine

**If our goal is prediction**

1. Establish what we'd like to predict
2. Estimate competing models
3. Compare with metric of accuracy / fit

# Overfitting

## Data for today

```{r fig.height = 3}
data(mtcars)
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point()
```

## The most common measure of model fit: $R^2$

\[R^2 = \frac{var(\textrm{outcome}) - var(\textrm{residuals})}{var(\textrm{outcome})}\]

\[R^2 = 1 - \frac{var(\textrm{residuals})}{var(\textrm{outcome})}\]

## $R^2$ in action

```{r zize = "tiny"}
m1<-quap(alist(
  mpg ~ dnorm(mu, sigma),
  mu<-a + bW * wt,
  a ~ dnorm(0, 10),
  bW ~ dnorm(0, 5),
  sigma ~ dexp(1)
  ), data = mtcars)
```

```{r echo = F}
d<-mtcars
R2_is_bad<-function(quap_fit){
  s<-sim(quap_fit, refresh=0)
  r<-apply(s,2,mean) - d$mpg
  1-var2(r)/var2(d$mpg)
}
R2_is_bad(m1)
```

$R^2$ tells us how much of the variance in the outcome variable is predictable based on the included predictor variable(s). Here: we can predict `r round(R2_is_bad(m1), 2) * 100` percent of the observed variance in $mpg$ after knowing $wt$

## Let's work with a sample of the data

```{r size = "tiny"}
car_sample<-mtcars %>% 
  sample_n(10)

d<-car_sample
```

For the linear model with weight as a predictor, $R^2 = $

```{r echo = F}
m1<-lm(mpg ~ wt, data = d)

summary(m1)$r.squared
```

## Can we improve the fit?

Yes! Let's use this linear function:

\[\mu = \alpha + \beta_1 W + \beta_2W^2\]

$R^2 = $

```{r echo = F}
m2<-lm(mpg ~ wt + I(wt^2), data = d)

summary(m2)$r.squared
```

## Can we improve the fit?

Yes!

\[\mu = \alpha + \beta_1 W + \beta_2W^2 + \beta_3W^3\]

$R^2 = $

```{r echo = F}
m3<-lm(mpg ~ wt + I(wt^2) + I(wt^3), data = d)

summary(m3)$r.squared
```

## Can we improve the fit?

Yes!

\[\mu = \alpha + \beta_1 W + \beta_2W^2 + \beta_3W^3 + \beta_4W^4\]

$R^2 = $

```{r echo = F}
m4<-lm(mpg ~ wt + I(wt^2) + I(wt^3) + I(wt^4), data = d)

summary(m4)$r.squared
```

## Can we improve the fit?

Yes!

\[\mu = \alpha + \beta_1 W + \beta_2W^2 + \beta_3W^3 + \beta_4W^4 +  \beta_5W^5 +  \beta_6W^6\]

$R^2 = $

```{r echo = F}
m5<-lm(mpg ~ wt + I(wt^2) + I(wt^3) + I(wt^4) +
         + I(wt^5) + I(wt^6) + I(wt^6), data = d)

summary(m5)$r.squared
```

## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  coord_cartesian(ylim = c(10, 34))
```

## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  coord_cartesian(ylim = c(10, 34))
```

## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = 3) + 
  coord_cartesian(ylim = c(10, 34))
```

## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = 3) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE, color = 4) + 
  coord_cartesian(ylim = c(10, 34))
```



## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = 3) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE, color = 4) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 5), se = FALSE, color = 5) + 
  coord_cartesian(ylim = c(10, 34))
```


## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = 3) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE, color = 4) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 5), se = FALSE, color = 5) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 6), se = FALSE, color = 6) + 
  coord_cartesian(ylim = c(10, 34))
```

## Compare these fits

```{r echo = F}
plot_dat<-data.frame(model = rep(c("m1", "m2", "m3", "m4", "m5"), 
                                 each = 10),

                     mpg = rep(d$mpg, 5),
                     wt = rep(d$wt, 5))
ggplot(plot_dat, aes(x = wt, y = mpg)) + 
  geom_point(size = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 1), se = FALSE, color = 1) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = 2) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = 3) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 4), se = FALSE, color = 4) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 5), se = FALSE, color = 5) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 6), se = FALSE, color = 6) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 7), se = FALSE, color = 7) + 
  coord_cartesian(ylim = c(10, 34))
```

## Overfitting and underfitting

- Adding complexity will improve goodness-of-fit measures like $R^2$
- But goodness-of-fit doesn't mean that we've modeled the process well, just that we've fit our *sample* well
- Adding too few parameters though can mean we aren't learning enough from the data
- *Goal:* balance model complexity with predictive accuracy

# How to address overfitting

## Regularizing priors

```{r echo = F}
plot_dat<-data.frame(x = seq(-3, 3, 0.01)) %>% 
  mutate(p1 = dnorm(x, 0, 1), 
         p2 = dnorm(x, 0, 0.5),
         p3 = dnorm(x, 0, 0.2))

ggplot(plot_dat, aes(x)) + 
  geom_line(aes(y = p3), lty = 1) +
  geom_line(aes(y = p2), lty = 2) + 
  geom_line(aes(y = p1), lty = 3)  +
  labs(subtitle = "N(0, 1) dotted, N(0, 0.5) dashed, N(0, 0.2) solid")
```

## Use these priors to fit our polynomial model

```{r size = "tiny"}
m0<-quap(alist(
  mpg ~ dnorm(mu, sigma),
  mu<-a + b * wt + b1 * wt^2 + b2 * wt^3 + b3 * wt^3 + b4 * wt^4,
  a ~ dnorm(0, 10),
  b ~ dnorm(0, 10),
  b1 ~ dnorm(0, 10),
  b2 ~ dnorm(0, 10),
  b3 ~ dnorm(0, 10),
  b4 ~ dnorm(0, 10),
  sigma ~ dexp(1)
), data = mtcars)

mReg<-quap(alist(
  mpg ~ dnorm(mu, sigma),
  mu<-a + b * wt + b1 * wt^2 + b2 * wt^3 + b3 * wt^3 + b4 * wt^4,
  a ~ dnorm(0, 1),
  b ~ dnorm(0, 1),
  b1 ~ dnorm(0, 1),
  b2 ~ dnorm(0, 1),
  b3 ~ dnorm(0, 1),
  b4 ~ dnorm(0, 1),
  sigma ~ dexp(1)
), data = mtcars)
```

## Narrower priors constrain overfitting

These priors force the model to learn less from the data. Flat priors allow the posterior to overfit the data.

```{r size = "tiny", fig.height = 4}
plot(coeftab(m0, mReg))
```

# Methods for comparing models

## How well can we predict cases that we didn't use to fit the model?

**Out of sample prediction** is a general set of methods that evaluate how well a model performs at predicting new cases. 

In general, we'd like to know how well our model predicts *new* observations, because it is easy to overfit on observed data.

## Training and test methods

Let's partition the data into two equal sets: a *training* sample that we'll use to fit the model, and a *test* sample that we'll use to evaluate predictive accuracy

We'll extend this later to a general approach: *leave-one-out cross-validation*

## Checking the fit for our 6 degree polynomial model

```{r echo = F}
set.seed(1)
index<-sample(1:nrow(mtcars), 16)
training<-mtcars %>% slice(index)
test<-mtcars %>% slice(-index)
m0<-lm(mpg ~ wt + I(wt^2) + I(wt^3) + I(wt^4) + I(wt^5) + I(wt^6), data = training)
mu<-predict(m0)

ggplot(training, aes(x = wt, y = mpg)) + 
  geom_point(size = 1, alpha = 0.5) + 
  geom_line(aes(y = mu)) + 
  coord_cartesian(ylim = c(10, 34), xlim = c(1, 6))

```

## Checking the fit for each of the models: compare to test data

```{r echo = F}
mu<-predict(m0, newdata = test)

ggplot(training, aes(x = wt, y = mpg)) + 
  geom_point(size = 1, alpha = 0.5) + 
  geom_point(data = test, aes(x = wt, y = mpg), size = 3) + 
  geom_line(aes(y = mu, x = test$wt)) + 
  coord_cartesian(ylim = c(10, 34), xlim = c(1, 6))

```

## Checking the fit for each of the models: compare to test data, less complex model

```{r echo = F}

m1<-lm(mpg ~ wt + I(wt^2), data = training)
mu<-predict(m1, newdata = test)

ggplot(training, aes(x = wt, y = mpg)) + 
  geom_point(size = 1, alpha = 0.5) + 
  geom_point(data = test, aes(x = wt, y = mpg), size = 3) + 
  geom_line(aes(y = mu, x = test$wt)) + 
  coord_cartesian(ylim = c(10, 34), xlim = c(1, 6))
```

## Leave-one-out cross validation

1. Define a model
2. Estimate the model, holding the first observation out
3. Predict the value for the held out observation, estimate prediction error
4. Repeat with 2:n observations
5. Average the error across each iteration

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-1),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(1), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-2),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(2), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-3),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(3), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-4),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(4), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-5),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(5), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-6),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(6), 
             aes(x = wt, y = mpg), color = "red")+ 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-7),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(7), 
             aes(x = wt, y = mpg), color = "red") + 
    coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-8),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(8), 
             aes(x = wt, y = mpg), color = "red") + 
  coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-9),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(9), 
             aes(x = wt, y = mpg), color = "red") + 
  coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Leave-one-out cross validation

```{r echo = F}
ggplot(training %>% slice(-10),
       aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_point(data = training %>% slice(10), 
             aes(x = wt, y = mpg), color = "red") + 
  coord_cartesian(ylim=c(10,37), xlim=c(1, 5))
```

## Implenting LOO-CV in R

```{r cache = T}
cv_quap(mReg)
```

PSIS provides an approximation of LOO-CV that is more computationally efficient

```{r}
PSIS(mReg)
```

# Model comparison using cross validation and information criteria

## General approach

This approach is appropriate for comparing the estimated *predictive* accuracy of models. It is not appropriate for causal inference.

1. Estimate competing models
2. Compute the indicator of interest
3. Evaluate relative model predictive performance

## Return to the plant fungus experiment

From the prior lecture and chapter 6: we conduct an experiment on the effect of an antifungal agent on plant growth. Conditioning on the presence of fungus confounds the relationship between the treatment and plant growth.

- fungus_0 is an intercept only model
- fungus_1 includes the treatment as a predictor
- fungus_2 includes both the treatment and fungus as a predictor

```{r echo = F}
N<-100
d<-data.frame(h0=rnorm(N, 10, 2), # generate initial height
              treatment = rep(c(0,1), each = N/2)) # random assignment to treatment

d<-d %>% 
  mutate(fungus = rbinom(N, size = 1, prob = 0.5 - treatment * 0.4), # p(fungus) is lower for treated
         h1 = h0 + rnorm(N, 5-3 * fungus, 1))

fungus_0<-quap(alist(
  h1 ~ dnorm(mu, sigma),
  mu<- h0 * p,
  p<- a + bt * treatment,
  a ~ dlnorm(0, 0.25),
  bt ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)

fungus_1<-quap(alist(
  h1 ~ dnorm(mu, sigma),
  mu<- h0 * p,
  p<- a + bt * treatment,
  a ~ dlnorm(0, 0.25),
  bt ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)

fungus_2<-quap(alist(
  h1 ~ dnorm(mu, sigma),
  mu<- h0 * p,
  p<- a + bt * treatment + bf * fungus,
  a ~ dlnorm(0, 0.25),
  bt ~ dnorm(0, 0.5),
  bf ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data = d)
```

## Compare these models using an information criterion

Information criteria compute an expected out-of-sample predictive score. AIC and BIC are routinely used, but better approaches now exist. We'll use WAIC (widely applicable information criteria). 

In general, information criteria have two components:

\[IC = \textrm{log probability of model} - \textrm{penalty term}\]

The penalty term (crudely) penalizes models for additional complexity. For two models with the same fit (log probability), the IC will prefer the less complex model

## Comparing model fits with WAIC

```{r}
compare(fungus_0, fungus_1, fungus_2)
```

- fungus_2 has the lowest WAIC score. This means that it is expected to predict new cases with the highest accuracy.
- The difference in WAIC between fungus_2 and fungus_1 is large and meaningful
- Note the dSE (difference standard error) value relative to dWAIC (the difference in WAIC between the lowest scoring model and all others) \pause
- Information criteria don't care about causation!

## Comparing model fits with PSIS

PSIS is an approximation of the LOO-CV method. It will warn you when there are influential observations that may bias the PSIS estimate. See 7.5.2 for a detailed example of how to address this using *robust regression*.

```{r}
compare(fungus_0, fungus_1, fungus_2, func = PSIS)
```

# Interactions

## Motivation for interactions

- A linear model assumes that predictors are independent
- It tells us about the expected relationship between X and Y, once we know Z  \pause
- What if we think the relationship between X and Y varies based on Z?

## Relationships between bad geography and a country's economic performance

- Countries with smoother terrain tend to have stronger economies. 
- However, economies in Africa appear to benefit from rough terrain. 
- This may be due to the protections that rugged terrain offered against the slave trade.

## The data

This data measures (among other things) 

- Terrain ruggedness (variance in topography)
- A country's gross domestic product per capita (the ratio of economic productivity to population) in 2000
- Continent

```{r size = "tiny"}
data(rugged)
glimpse(rugged %>% select(country, rugged, cont_africa, rgdppc_2000))
```

## The relationships inside and outside Africa: separate regressions

```{r echo = F}
ggplot(rugged %>% filter(cont_africa==1), 
       aes(x = rugged, y = log(rgdppc_2000))) + 
  geom_point(color = "blue", alpha = 0.5) + 
  geom_smooth(method = "lm",  color = "blue") + 
  geom_point(data = rugged %>% filter(cont_africa==0), 
       aes(x = rugged, y = log(rgdppc_2000)),
             color = "red", alpha = 0.5) + 
  geom_smooth(data = rugged %>% filter(cont_africa==0), 
       aes(x = rugged, y = log(rgdppc_2000)),
       method = "lm", color = "red") + 
  coord_cartesian(xlim=c(0,7), ylim = c(6,11)) + 
  labs(subtitle = "Red: non-African nation, Blue: African nation")
```

## Set up the data for analysis

```{r size = "tiny"}
d<-rugged %>% 
  mutate(log_gdp = log(rgdppc_2000),
         log_gdp.s = scale(log_gdp),
         rugged.s =scale(rugged)) %>% 
  filter(complete.cases(log_gdp))

m8.1<-quap(alist(
  log_gdp.s~dnorm(mu,sigma),
  mu<-a+b*rugged.s,
  a~dnorm(0, 0.1),
  b~dnorm(0,0.3),
  sigma~dexp(1)),
  data=d)

precis(m8.1)
```

## What if we add intercepts for African / non-African nations?

```{r}
d<-d %>% 
  mutate(cont_africa = cont_africa + 1)

m8.2<-quap(alist(
  log_gdp.s~dnorm(mu,sigma),
  mu<-a[cont_africa]+b*rugged.s,
  a[cont_africa]~dnorm(0, 0.1),
  b~dnorm(0,0.3),
  sigma~dexp(1)),
  data=d)

precis(m8.2, depth = 2)
compare(m8.1, m8.2)
```

## What do model expectations look like?

```{r size = "scriptsize"}
## generate counterfactual data for sim
plot_dat<-data.frame(rugged.s = 
                       rep(seq(-1, 4, length.out = 100), 2),
                     cont_africa = rep(c(1, 2), each = 100))
sims<-link(m8.2, plot_dat) # draw posterior samples
sims_mu<-apply(sims, 2, mean) # calculate mean mu
sims_pi<-apply(sims, 2, PI) # calculate 89% PI
plot_dat<-plot_dat %>% # attach for plotting
  mutate(logGDP = sims_mu,
         logGDP_lwr = sims_pi[1,],
         logGDP_upr = sims_pi[2,])
```

## Plot model expectation $\mu$

```{r size = "tiny", fig.height = 4}
ggplot(plot_dat, aes(x = rugged.s, y = logGDP,
                     group = cont_africa)) + 
  geom_line(aes(color = factor(cont_africa))) + 
  geom_ribbon(alpha = 0.2, aes(ymin = logGDP_lwr, ymax = logGDP_upr)) +
  geom_point(data = d, aes(x = rugged.s, y = log_gdp.s, color = factor(cont_africa)), alpha = 0.2)
```

## Model specification

The linear component of our Africa / not - Africa intercept model is:

\[\mu = \alpha_{\textrm{Africa}[i]} + \beta r_i\] \pause

This specification estimates one intercept for African countries, and one for non-African countries. Slopes are identical for all countries.

## Model specification: adding an interaction

Adding a slope for each group is easy:

\[\mu = \alpha_{\textrm{Africa}[i]} + \beta_{\textrm{Africa}[i]} r_i\] \pause

This is the interaction: the slope of ruggedness now depends on continent.

## Estimating the interaction model

```{r}
m8.3<-quap(alist(
  log_gdp.s~dnorm(mu,sigma),
  mu<-a[cont_africa]+b[cont_africa]*rugged.s,
  a[cont_africa]~dnorm(0, 0.1),
  b[cont_africa]~dnorm(0,0.3),
  sigma~dexp(1)),
  data=d)

compare(m8.1, m8.2, m8.3)
```

## Visualizing the interaction

```{r fig.height = 3, size = "tiny"}
sims<-link(m8.3, plot_dat) # draw posterior samples
sims_mu<-apply(sims, 2, mean) # calculate mean mu
sims_pi<-apply(sims, 2, PI) # calculate 89% PI
plot_dat<-plot_dat %>% # attach for plotting
  mutate(logGDP = sims_mu,
         logGDP_lwr = sims_pi[1,],
         logGDP_upr = sims_pi[2,])

ggplot(plot_dat, aes(x = rugged.s, y = logGDP,
                     group = cont_africa)) + 
  geom_line(aes(color = factor(cont_africa))) + 
  geom_ribbon(alpha = 0.2, aes(ymin = logGDP_lwr, ymax = logGDP_upr)) +
  geom_point(data = d, aes(x = rugged.s, y = log_gdp.s, color = factor(cont_africa)), alpha = 0.2)
```

## Continuous interactions

- We just estimated an interaction between a *categorical* variable and a *continuous variable* 
- This results in $k$ slopes, where $k$ is the number of categories in the categorical variable
- If we interact a continuous varible with another continuous variable we estimate an infinite number of slopes (!). 
- Directly interpreting posterior parameter estimates is very difficult

## The example data

- Plant growth depends on light and water
- If we've got light and no water, no growth
- If we've got water and no light, no growth
- How do tulip blooms vary as a function of shade and water?

```{r size = "tiny"}
data(tulips)
head(tulips)
```

## Fitting a model without interactions

Our linear function for this model will be:

\[\mu = \alpha + \beta_wW_i + \beta_sS_i\]

```{r size = "tiny"}
d<-tulips %>% 
  mutate(blooms.s = blooms / max(blooms),
         water.s = water - 2,
         shade.s = shade - 2)

tulip0<-quap(alist(
  blooms.s ~ dnorm(mu, sigma),
  mu <- a + bw * water.s + bs * shade.s,
  a ~ dnorm(0.5, 0.25),
  bw ~ dnorm(0, 0.25),
  bs ~ dnorm(0, 0.25),
  sigma ~ dexp(1)
), data = d)
```

## Add the interaction

Interactions allow for the relationship between $B$ and $W$ to depend on $S$ (equivalently $B$ and $S$ depends on $W$).

\[\mu = \alpha + \beta_wW_i + \beta_sS_i + \beta_{sw}W_iS_i\]

```{r size = "tiny"}
tulip1<-quap(alist(
  blooms.s ~ dnorm(mu, sigma),
  mu <- a + bw * water.s + bs * shade.s + bws * water.s * shade.s,
  a ~ dnorm(0.5, 0.25),
  bw ~ dnorm(0, 0.25),
  bs ~ dnorm(0, 0.25),
  bws ~ dnorm(0, 0.25),
  sigma ~ dexp(1)
), data = d)
```

## Look at the posterior 

```{r size = "tiny"}
compare(tulip0, tulip1)
precis(tulip1)
```

- $\alpha$ is the intercept, same as usual
- $\beta_w$ is now the slope for water when shade is zero
- $\beta_s$ is the slope for shade when water is zero
- $\beta_{ws}$ moves the slope by $W\times S$ when neither is zero

This is very difficult to interpret... Don't try! Let's visualize instead.

## The plan for a visual

- Let's visualize the counterfactual relationship between water and blooms for a range of values of shade. 
- This means multiple plots, partitioning the continuous into ordered categories
- We want a full range of water along a range of values of shade
- If we want to see $k$ values of water and $j$ values of shade, we'll have $k \times j$ scenarios in our counterfactual data

```{r size = "tiny"}
plot_dat<-data.frame(water.s = rep(seq(-1, 1, length.out = 10),3),
                     shade.s = rep(c(-1, 0, 1), each = 10))

head(plot_dat)
```

## Plotting it

```{r size = "tiny", fig.height = 3}
mus<-link(tulip1, plot_dat)
mu_mn<-apply(mus, 2, mean)
mu_pi<-apply(mus, 2, PI)
plot_dat<-plot_dat %>% 
  mutate(mu = mu_mn,
         mu_lwr = mu_pi[1,],
         mu_upr = mu_pi[2,])

ggplot(plot_dat, aes(x = water.s, y = mu,
                     ymin = mu_lwr, ymax = mu_upr)) + 
  geom_line() + 
  geom_ribbon(alpha = 0.5) + 
  facet_wrap(~shade.s)+ 
  labs(subtitle = "Expected blooms by water (x) and shade (facets)")
```

## Pushing this further

```{r echo = F}
plot_dat<-data.frame(water.s = rep(seq(-1, 1, length.out = 9),9),
                     shade.s = rep(seq(-1, 1, length.out = 9), each = 9))

mus<-link(tulip1, plot_dat)
mu_mn<-apply(mus, 2, mean)
mu_pi<-apply(mus, 2, PI)
plot_dat<-plot_dat %>% 
  mutate(mu = mu_mn,
         mu_lwr = mu_pi[1,],
         mu_upr = mu_pi[2,])

ggplot(plot_dat, aes(x = water.s, y = mu,
                     ymin = mu_lwr, ymax = mu_upr)) + 
  geom_line() + 
  geom_ribbon(alpha = 0.5) + 
  facet_wrap(~shade.s) + 
  labs(subtitle = "Expected blooms by water (x) and shade (facets)")
```

## Wrapping up

- Homework: Complete problem 8H4 from the book (Chapter 8 Practice)
- We'll review this material and discuss in lab on Tuesday