---
title: "Introduction to the course and Bayesian data analysis"
author: "Frank Edwards"
date: "1/31/2020"
output: binb::metropolis
---

```{r setup, include=FALSE}
library(rethinking)
library(gridExtra)
library(tidyverse)

knitr::opts_chunk$set(tidy = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

## Sampling from the posterior

- We use Bayesian methods to *approximate* the posterior distribution
- We can then sample parameters from the estimated posterior to learn about parameters or to simulate predictions
- We can plot densities, directly sample *credible intervals*, compare differences in means, all without relying on a theoretical *sampling distribution*, like we do with frequentist methods 

## Integrals can be hard

Let's say we want to know how much probability mass there is within $\pm 1.4$ standard deviations of 0 for $x \sim N(0,1)$.

- The Normal probability density function (PDF) is: $\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}$ \pause
- To answer our question exactly, we can take the integral of the PDF from $-1.4$ to $1.4$ or:

$$\int_{-1.4}^{1.4} \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2} dx$$ \pause

I don't want to do this, and I suspect neither do you. \pause

**Note**: for defined probability distributions, we can use the, like dnorm(). However, most of our posteriors won't be so simple to work with.

## But simulation is easy!

1. Sample from the target distribution
2. Summarize our quantity of interest

```{r, fig.align="center", fig.height = 2}
n_samples<-10000
samples<-rnorm(n = n_samples, mean = 0, sd = 1)
ggplot(data.frame(samples), aes(x=samples)) + geom_histogram()
```

## Using samples to calculate quantities of interest

What are the mean and SD of this paramter? 

```{r size = "tiny"}
mean(samples)
sd(samples)
```
How much mass is within $0 \pm 1.4$?

```{r size = "tiny"}
samples_df<-data.frame(samples)
samples_df %>% 
  filter(samples>=-1.4 & samples<=1.4) %>% 
  summarise(mass = n()/n_samples)
```

## Estimation strategies

Because we are computing the product of probability distributions there sometimes aren't exact solutions. We'll rely on 3 algorithms to *approximate* posterior distributions to condition the prior on the likelihood of the data. 

- Grid approximation (check!)
- Quadratic approximation (today!)
- Markov Chain Monte Carlo (MCMC) (week 7 or 8 on)

## Grid approximation algorithm

1. Define the grid 
2. Compute the prior for each parameter value on the grid
3. Compute the likelihood for each parameter value on the grid
4. Multiply the prior by the likelihood
5. Divide by the sum of all values

## Grid approximation in R

```{r}
length <- 50
### make our grid
grid<-seq(from = 0, to = 1, length.out = length)
prior  <-  rep(1, length)
likelihood  <-  dbinom(6, size = 9, prob = grid)
posterior <- prior * likelihood / sum(prior * likelihood)
```

## Sampling from a grid-estimated posterior

- We've estimated the posterior probability density for each value on the grid \pause
- We can draw random samples from this distribution. With a large enough number of samples, we can closely approximate the distribution \pause
- Using these samples, we can learn alot about the parameter of interest

## Draw samples of proportion water from grid estimated posterior

```{r tidy = F}
post_samples<-sample(
  grid,
  prob = posterior,
  size = 10,
  replace = T)

round(post_samples,2)
```

## Our estimate of *p*, 10 samples

```{r fig.height = 3}
plot_dat<-tibble(post_samples)
ggplot(plot_dat, 
       aes(x = post_samples)) + 
  geom_density(adjust = 1/2,
               fill = "plum")+ 
  coord_cartesian(xlim=c(0,1))
```

## The impact of sample size on the posterior density: 100 samples

```{r tidy = F, size = "scriptsize", fig.height = 3}
post_samples<-sample(
  grid,
  prob = posterior,
  size = 100,
  replace = T)

plot_dat<-tibble(post_samples)
ggplot(plot_dat, 
       aes(x = post_samples)) + 
  geom_density(adjust = 1/2,
               fill = "burlywood") + 
  coord_cartesian(xlim=c(0,1))
```

## The impact of sample size on the posterior density: 1000 samples

```{r tidy = F, size = "scriptsize", fig.height = 3}
post_samples<-sample(
  grid,
  prob = posterior,
  size = 1000,
  replace = T)

plot_dat<-tibble(post_samples)
ggplot(plot_dat, 
       aes(x = post_samples)) + 
  geom_density(adjust = 1/2,
               fill = "tomato")+ 
  coord_cartesian(xlim=c(0,1))
```

## The impact of sample size on the posterior density: 10000 samples

```{r tidy = F, size = "scriptsize", fig.height = 3}
post_samples<-sample(
  grid,
  prob = posterior,
  size = 10000,
  replace = T)

plot_dat<-tibble(post_samples)
ggplot(plot_dat, 
       aes(x = post_samples)) + 
  geom_density(fill = "dodgerblue")+ 
  coord_cartesian(xlim=c(0,1))
```

## The impact of sample size on the posterior density: 100000 samples

```{r tidy = F, size = "scriptsize", fig.height = 3}
post_samples<-sample(
  grid,
  prob = posterior,
  size = 100000,
  replace = T)

plot_dat<-tibble(post_samples)
ggplot(plot_dat, 
       aes(x = post_samples)) + 
  geom_density(fill = "mediumorchid") + 
  coord_cartesian(xlim=c(0,1))
```

## So what now?

What questions do we typically ask about a parameter? \pause

- What is the mean / expected value of the parameter?
- How certain are we about the location of the parameter?

## Using posterior samples

What is $E(p)$ \pause

```{r size = "scriptsize"}
mean(post_samples)
```
\pause
How certain are we about the location of $p$? Where is 92 percent of the posterior probability? \pause

```{r size = "scriptsize"}
quantile(post_samples, c(0.04, 0.96))
```
\pause
Conditional on the data and our assumptions (priors, likelihood), we can describe the posterior *without* appealing to theoretical replications (!!!)

## Approximation via sampling, brute force when exact solutions are difficult / undefined

```{r echo = F, message = F, warning = F}
## real curve
par(mfrow = c(2,1))
counts<-1:9
plot(counts/9, dbinom(counts, 9, 6/9), type = "h", 
         main = "Binomial(9, 2/3), exact")
plot(density(post_samples), 
     main = "Binomial(9, 2/3), approximated")
```

```{r include = F}
dev.off()
```

## Quadratic approximation

1. Assume our posterior is approximately Normal (often reasonable)
2. Find the mode of the psoterior
2. Estimate curvature at the logarithm of the posterior with a parabola
3. Use the resulting  Gaussian / Normal distribution for inference
4. With enough data $\textsf{quap} \rightarrow \textsf{MLE}$

## Using quadratic approximation in R

```{r size = "scriptsize"}
### let's treat 1 as water, 0 as land
dat<-list(W = 6, L = 3)

formula_list<-alist(
  # likelihood
  W ~ dbinom(W+L, p),
  # prior
  p ~ dunif(0,1)
)

model1<-quap(
  formula_list,
  data = dat
)

summary(model1)
```

## Extract posterior samples

```{r, fig.height = 3, size = "tiny"}
post_samples<-extract.samples(model1)

p1<-ggplot(post_samples,
       aes(y = p, x = 1:nrow(post_samples))) + 
  geom_point(alpha = 0.2, color = "magenta") +
  xlab("Sample number")

p2<-ggplot(post_samples,
       aes(x = p)) + 
  geom_density(fill = "magenta")

grid.arrange(p1, p2, ncol = 2)
```

## Using this object

```{r size = "scriptsize"}
str(post_samples)
summary(post_samples)
```

## Learning from the posterior

Questions we can ask with posterior samples:

- How much posterior probability lies (below/above/between) some parameter value(s)?
- Which parameter values mark the (lower/upper) n% of the posterior probability?
- Which parameter value has the highest posterior probability?

## How much posterior probability lies below/above/between some parameter value(s)?

We can simply filter the samples, then divide by the size of the posterior sample.

**Q:** What is the posterior probability that there is less than 60 percent water on the globe, conditional on our model and the data?

```{r}
post_samples %>% 
  filter(p<0.6) %>% 
  summarise(p = n()/nrow(post_samples))
```

## How much posterior probability lies below/above/between some parameter value(s)?

**Q:** What is the posterior probability that there is between 60 percent and 90 percent water on the globe, conditional on our model and the data?

```{r}
post_samples %>% 
  filter(p>=0.6 & p<=0.9) %>% 
  summarise(p = n()/nrow(post_samples))
```

## Which parameter values mark the (lower/upper) n% of the posterior probability?

**Q:** What is the parameter region in which 89% of the posterior probability mass lies? \pause

```{r}
quantile(post_samples$p, c(0.05, 0.94))
quantile(post_samples$p, 0.89)
```

Thoughts on the differences between these two intervals?

## What the intervals look like

```{r echo = F}
ggplot(post_samples,
       aes( x = p)) + 
  geom_density() + 
  geom_vline(xintercept = quantile(post_samples$p, 0.89)) + 
  geom_vline(xintercept = quantile(post_samples$p, 0.05), linetype ="dashed") +
  geom_vline(xintercept = quantile(post_samples$p, 0.94), linetype ="dashed") + 
  labs(subtitle = "Solid line indicates lower 89 percent CI \nDashed indicates CI centered at 50th percentile of p")
```

## Confidence intervals versus Bayesian credible / compatible intervals

- Confidence interval: If we replicated the experiment many times, the (fixed) true value would lie within this interval 89 percent of the time. \pause
- Credible interval: Conditional on our data and model (priors, likelihood), 89 percent of the compatible parameter values lie within this range. 

## Confidence intervals versus Bayesian credible / compatible intervals

-  The frequentist confidence approach assumes the parameter value is fixed, randomness results from sampling the data \pause
- The Bayesian approach assumes that information about the parameter is random, not fixed \pause
- Neither is correct, but the interpretation of the Bayesian interval has a far more intuitive interpretation

**Note:** There's nothing inherently scientific about 0.95. It is merely convention. Other intervals are just as valid. McElreath likes .89 because it is prime. I like 0.92 or 0.90 because they are even. 

## Point estimates

Which parameter value has the highest posterior probability? 

```{r}
chainmode(post_samples$p, adj = 0.01)
```

This is the maximum a posteriori (MAP) estimate. \pause

If our posterior is approximately symmetric, the MAP and median will be similar

```{r}
median(post_samples$p)
```

## Simulating prediction

We've learned how to describe the parameter *p* with posterior samples. \pause

What would happen if we re-ran the experiment? \pause

- **Posterior predictive simulation** incorporates updated information on the parameter into predictions of new values of our observed outcome variable (W, L) 

## Posterior prediction algorithm

1. Sample from the posterior distribution
2. Use these sampled posterior parameter values to sample new values from the likelihood

\pause

```{r size = "tiny"}
# Pull samples of p from quap estimated model1
p_samples<-extract.samples(model1) 
# because of impossible p >1 (Gaussian)
p_samples<-p_samples %>%  
  mutate(p = ifelse(p>1, 1, p))
## sample from likelihood
WL_predictions<-rbinom(1e4, size = 9, prob = p_samples$p) 
table(WL_predictions)
```

## Visualize the predictions

```{r size = "tiny", fig.height = 3}
ggplot(data.frame(WL_predictions), 
       aes(x = WL_predictions)) + 
  geom_histogram() + 
  scale_x_continuous(breaks=0:9) +
  labs(title = "Posterior predictions of W")
```

## The impact of uncertainty in p on predictions

```{r size = "tiny", fig.height = 3}
ggplot(p_samples, aes(x = p)) + 
  geom_histogram()
```

## The impact of uncertainty in p on predictions: p = posterior median

```{r size = "tiny", fig.height = 3}
## set p at the median of the posterior 
samples<-rbinom(1e4, 9, median(p_samples$p))
ggplot(data.frame(samples), aes(x = samples)) + 
  geom_histogram()
```

## The impact of uncertainty in p on predictions: p = posterior 5th percentile

```{r size = "tiny", fig.height = 3}
## set p at the 5th percentile of the posterior 
samples<-rbinom(1e4, 9, quantile(p_samples$p, 0.05))
ggplot(data.frame(samples), aes(x = samples)) + 
  geom_histogram()
```

## The impact of uncertainty in p on predictions: p = posterior 95th percentile

```{r size = "tiny", fig.height = 3}
## set p at the 95th percentile of the posterior 
samples<-rbinom(1e4, 9, quantile(p_samples$p, 0.95))
ggplot(data.frame(samples), aes(x = samples)) + 
  geom_histogram()
```

## Posterior predictive distributions propagate uncertainty in p into predictions

```{r size = "tiny", fig.height = 3}
ggplot(data.frame(WL_predictions), 
       aes(x = WL_predictions)) + 
  geom_histogram() + 
  scale_x_continuous(breaks=0:9) +
  labs(title = "Posterior predictions of W")
```

## Prior prediction

We can also use simulation to better understand and select priors \pause

```{r size = "tiny"}
### our prior
formula_list

prior_samples<-runif(1e4, 0, 1)

head(prior_samples)
```

## Visualize the prior predictions

```{r size = "tiny", fig.height = 3}
ggplot(data.frame(prior_samples), 
                  aes(x = prior_samples)) + 
  coord_cartesian(xlim = c(0, 1)) +
  geom_histogram(bins = 20) 
```

## Summary

- Simulation is a fundamental tool in Bayesian data analysis
- We learn a lot from visualizing samples from our estimated prior, posterior, and posterior predictive distributions
- These visuals help you carefully check assumptions and model performance
- Posterior prediction is a first step to moving past the typical point estimate / standard error presentation of results, and toward visual and interval-driven presentations
- HW 2 is posted in ./hw
- HW 1 solutions will be posted in ./hw
