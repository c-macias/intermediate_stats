---
title: "Recoding variables - Interpreting logistic models"
author: "Frank Edwards"
date: "2/22/2019"
output: binb::metropolis
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(broom)
set.seed(1)

options(xtable.comment = FALSE)
theme_set(theme_minimal())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = TRUE, size = "small")
```

# Review Homework,

# Logistic regression part 2

## The logit and logistic functions

$$\textrm{logit}(p) = \textrm{log}\left(\frac{p}{1-p}\right)=\alpha$$

$$\textrm{logit}^{-1}(\alpha) = \textrm{logistic}(\alpha) = \frac{\textrm{exp}(\alpha)}{\textrm{exp}(\alpha) + 1}$$

## Let's define a function in R for logit 

```{r}
logit<-function(p){
  alpha<-log(p / (1-p))
  return(alpha)
}
```

- What should we expect to see if we run logit(0.5) \pause
- What about logit(0.6)
- logit(0.9)?

## What does it do?

```{r}
logit(0.5)
logit(0.6)
logit(0.9)
```

## Functions in R can run over vectors!

```{r}
p<-c(0.5, 0.6, 0.9)
logit(p)
```

## What does a logit look like with probabilities on [0,1]

```{r, fig.height = 3}
p<-seq(from = 0, to = 1, by = 0.001)
p_dat<-data.frame(p = p, logit_p = logit(p))
ggplot(p_dat, aes(x = p, y = logit_p)) + geom_point()
```

## Defining the inverse logit (logistic) function
Remember: $$\textrm{logit}^{-1}(\alpha) = \textrm{logistic}(\alpha) = \frac{\textrm{exp}(\alpha)}{\textrm{exp}(\alpha) + 1}$$

```{r}
inv.logit<-function(alpha){
  p <- exp(alpha) / (exp(alpha) + 1)
  return(p)
}
```

- What does inv.logit(0) return?
- What does inv.logit(10) return?
- What does inv.logit(-10) return?

## The shape of the logistic function

```{r, fig.height = 3}
alpha <- seq(from = -7, to = 7, by = 0.01)
p_dat<-data.frame(alpha = alpha, logistic_alpha = inv.logit(alpha))
ggplot(p_dat, aes(x = alpha, y = logistic_alpha)) + geom_point()
```

## Logit and logistic are inverses

```{r}
p<-c(0.1, 0.3, 0.5, 0.7, 0.9)
alpha<-logit(p)
alpha
inv.logit(alpha)
```

## OK - so why do I need this?

- Remember that logistic regression is a GLM with a logit link function \pause
- A GLM takes the form: $g(y) = \textrm{X}\beta$ \pause
- Logistic regression is the special case where g is the logit function: $\textrm{logit}(y) = \textrm{X}\beta$ \pause
- A logistic regression model returns $\textrm{X}\beta$ on the logit scale \pause
- How can we convert $\textrm{x}\beta$ to something useful?

## Let's return to the grad school admission example

```{r}
admits<-read_csv("./data/binary.csv")
summary(admits)
```

## Is rank a numeric?

Is the distance between 1 and 2 symmetric to the distance between 2 and 3? \pause

Not really. Let's make it a factor. \pause

```{r}
admits<-admits%>%
  mutate(rank = factor(rank))
## as.character() would be fine too
```

## Let's explore our outcome

Huh, all this tells us is mean(admits) = `r mean(admits$admit)`

```{r fig.height=3}
hist(admits$admit)
```

## Let's look at this as the distribution of the probability of admissions across the data

- First, fit an intercept-only logistic regression model

```{r}
m0<-glm(admit ~ 1, data = admits, family = "binomial")
m0_est<-tidy(m0)
```

- What does this model tell us? 

## What does this model tell us?

```{r}
m0_est$estimate ## log odds
exp(m0_est$estimate) ## odds
inv.logit(m0_est$estimate) ## probability
mean(admits$admit) ## mean admission probability
```

## Or visually - fascinating!

```{r, fig.height = 3}
yhat<-predict(m0, type = "response")
hist(yhat)
```

## Let's add a predictor

```{r}
m1<-glm(admit ~ 1 + gre, data = admits, family = "binomial")
m1_est<-tidy(m1)
m1_est
```

## Before and after - what's going on?

```{r}
par(mfrow=c(1,2))
hist(predict(m0, type = "response"), main = "Intercept only")
hist(predict(m1, type = "response"), main = "With GRE predictor")
```


## To ease interpretation, let's scale gre

Scale mean-centers and SD scales variables: $\textrm{scale}(x_i) = \frac{x_i - \bar{x}}{sd(x)}$

## Re-estimate the model: much nicer to look at
```{r}
admits<-admits%>%
  mutate(gre = as.numeric(scale(gre)))
m1<-glm(admit ~ 1 + gre, data = admits, family = "binomial")
m1_est<-tidy(m1)
m1_est
```

## Interpret the model

```{r}
m1_est
```


Remember: $\textrm{logit}(y) = \textrm{X}\beta = \textrm{log}\left(\frac{y}{1-y}\right)$

So: $y = \textrm{logit}^{-1}(\textrm{X}\beta) = \frac{\textrm{exp}(\textrm{X}\beta)}{\textrm{exp}(\textrm{X}\beta) + 1}$ \pause

- What is $\beta_0$? \pause
- What is $\beta_1$?

## Refresher on exponentials

$$e^{y_1 + y_2} = e^{y_1} e^{y_2}$$ \pause

and 

$$e^{y_1 - y_2} = \frac{e^{y_1}}{e^y_2}$$ \pause

so how can we rewrite: 

$$\textrm{exp}(\textrm{logit}(y)) = \frac{y}{1-y} = e^{\beta_0 + \beta_1x_1} $$

## Non-linear relationships

On the log scale, $\beta_0$ and $\beta_1$ are related to y multiplicatively because

$$e^{\beta_0 + \beta_1x_1} = e^{\beta_0}e^{\beta_1x_1}$$

## Odds 

Odds are defined as the probability of the event occurring divided by the probability of probability of the event not occurring. To obtain odds in a logistic regression, we exponentiate both sides: 

$$\frac{y}{1-y} = e^{\beta_0 + \beta_1x_1}$$ \pause

The odds of $y==1$ are simply $e^{X\beta}$

## Odds ratios

The odds ratio is the ratio of two odds - or the proportional change in odds. We can obtain an isolated estimate for the relationship between $\beta_1x_{1i}$ and $y$ this way:

$$\frac{Odds(y |x_1 = 1)}{Odds(y|x_1 = 0)} =  \frac{e^{X\beta + \beta_1}} {e^{X\beta}} = \frac{e^{X\beta} \times e^{\beta_1}} {e^{X\beta}} =  e^{\beta_1}$$

The odds ratio can be interpreted as the change in odds of $y==1$ for a one-unit change in $x_1$. 

## Interpreting odds ratios

- Odds ratios appear convenient - $e^{\beta_1}$ is a percent change in $y$ for a one-unit change in $x_1$ \pause

How do they work?

## In our example: what do these figures mean?

```{r size = "scriptsize"}
new_dat<-c(1,0) # for scale(gre) == 0, mean score
odds_0<-exp(new_dat%*%m1_est$estimate)
odds_0
new_dat1<-c(1,1)
odds_1<-exp(new_dat1%*%m1_est$estimate)
odds_1
odds_1/odds_0 # odds ratio
exp(m1_est$estimate[2]) # exp(beta_1)
```

## Interpreting the odds ratio

The odds of admission are `exp(m1_est$estimate[2])` times higher for a student with a GRE score one standard deviation above the mean than they are for a student with a mean GRE score. \pause

Any trouble you can anticipate here? \pause

## Problems with the odds ratio

```{r}
p<-c(0.1, 0.2, 0.5, 0.8, 0.9)
odds<-function(p){p/(1-p)}
inv_odds<-function(o){o/(1+o)}
odds_p<-odds(p)
OR<-exp(m1_est$estimate[2])
inv_odds(OR + (OR * odds_p)) - p
```

## A visual example: the "effect" of 1 SD increase in GRE scores on Pr(admit==1)

```{r, echo = FALSE}
new_dat<-data.frame(gre=seq(-3, 0.8, by = 0.001))
p<-predict(m1, newdata = new_dat, type = "response")
new_dat2<-new_dat%>%mutate(gre = gre + 1)
p2<-predict(m1, newdata = new_dat2, type = "response")
par(mfrow=c(1,3))
plot_dat<-data.frame(p = p2, gre = new_dat2$gre, type = "P(admit)")
plot_dat<-plot_dat%>%
  bind_rows(data.frame(p = p2 - p, gre = new_dat2$gre, type = "P(admit|gre+1)-P(admit)"))
            
ggplot(plot_dat, aes(x = gre, y = p, color = type)) + geom_line()

```

## It is easy enough to work on the probability scale

To obtain predicted probabilities of the observed:

- p_hat<-inv.logit(predict(m1))
- p_hat<-predict(m1, type = "response")

## To obtain intervals

```{r size = "scriptsize", fig.height = 2}
preds<-predict(m1, se.fit = TRUE)
p_hat<-data.frame(gre = admits$gre,
                  p = inv.logit(preds$fit),
                  upper = inv.logit(preds$fit + 2*preds$se.fit),
                  lower = inv.logit(preds$fit - 2*preds$se.fit))

ggplot(p_hat, aes(x = gre, y = p, ymin = lower, ymax = upper)) + 
  geom_line() + 
  geom_ribbon(alpha = 0.5)
```

## Logistic regression as a classifier

We can use logistic regression to predict values of a binary variable. We can then assess how well our model performs relative to classifying cases relative to the observations. \pause

What is the meaning of a:

- a true positive rate (sensitivity)? \pause
- a true negative rate (specificity)? 

## Returning to our model

$$Pr(admit=1) = logit^{-1}(\beta_0 + \beta_1GRE)$$ \pause

What does our model predict for each applicant?

```{r}
phat<-predict(m1, type = "response")
head(cbind(phat, admits))
```

## Evaluating our predictions and its performace

```{r size = "scriptsize"}
phat<-predict(m1, type = "response")
summary(phat)
threshold<-quantile(phat, 0.75)
preds<-data.frame(obs = admits$admit==1, pred = phat>threshold)
table(preds$obs, preds$pred)
sum((preds$obs==1) & (preds$pred==1))/sum(preds$obs==1) # True positive rate
sum((preds$obs==0) & (preds$pred==0))/sum(preds$obs==0) # True negative rate
```

## What happens to predictive performance when we add a predictor to the model?
```{r size = "scriptsize"}
m2<-glm(admit ~ gre + gpa, data = admits, family = "binomial")
phat<-predict(m2, type = "response")
threshold<-quantile(phat, 0.75)
preds<-data.frame(obs = admits$admit==1, pred = phat>threshold)
sum((preds$obs==1) & (preds$pred==1))/sum(preds$obs==1) # True positive rate
sum((preds$obs==0) & (preds$pred==0))/sum(preds$obs==0) # True negative rate
```

## What happens to predictive performance when we add a predictor to the model?
```{r size = "scriptsize"}
m3<-glm(admit ~ gre + gpa + rank, data = admits, family = "binomial")
phat<-predict(m3, type = "response")
threshold<-quantile(phat, 0.75)
preds<-data.frame(obs = admits$admit==1, pred = phat>threshold)
sum((preds$obs==1) & (preds$pred==1))/sum(preds$obs==1) # True positive rate
sum((preds$obs==0) & (preds$pred==0))/sum(preds$obs==0) # True negative rate
```

## How can we use this to make decisions? ROC Curves

```{r size = "tiny"}
roc_dat<-data.frame("obs" = admits$admit, "phat" = phat)

simple_roc <- function(labels, scores){
  labels <- labels[order(scores, decreasing=TRUE)]
  data.frame(TPR=cumsum(labels)/sum(labels), FPR=cumsum(!labels)/sum(!labels), labels,
             probs=scores[order(scores, decreasing = TRUE)])
}

roc_out<-simple_roc(roc_dat$obs, roc_dat$phat)
1/sum(roc_dat$obs)
1/sum(!(roc_dat$obs))
slope<-sum(!(admits$admit))/sum(admits$admit)
head(roc_out)
```


## Plotting in ROC space

![](./vis/roc-space.png)

## Plotting the ROC curve

```{r, fig.width = 3, fig.height=3}
ggplot(roc_out,
       aes(x=FPR, y = TPR))+ 
  geom_line() + 
  geom_abline(slope = 1,  lty = 2)
```

## Comparing models

```{r size = "scriptsize"}
models<-list(m0, m1, m2, m3)
preds<-lapply(models, function(x) {
  predict(x, type="response")})
str(preds)
```

## Comparing models (cont.)

```{r}
roc_temp<-list()
for(i in 1:length(preds)){
  roc_temp[[i]]<-simple_roc(labels = admits$admit,
             scores = preds[[i]])
}
roc_dat<-bind_rows(roc_temp)
roc_dat<-roc_dat%>%
  mutate(model = rep(c("Intercept_only", "GRE", "GRE+GPA", "GRE+GPA+RANK"), 
                       each = nrow(admits)))
```

## Plotting this monstrosity

```{r, echo = FALSE}
ggplot(roc_dat,
       aes(x=FPR, y = TPR, color = model))+ 
  geom_line() + 
  geom_abline(slope = 1, lty = 2)
```

## Selecting a threshold

We can use many thresholds:

- We can optimize overall accuracy - this will be the inflection point in the curve

## Selecting a threshold

```{r echo = FALSE, fig.height = 4}
ggplot(roc_dat,
       aes(x=FPR, y = TPR, color = model))+ 
  geom_line() + 
  geom_abline(slope = 1, lty = 2) + 
  geom_vline(xintercept = 0.25, lty=3) + 
  geom_hline(yintercept = 0.57, lty=3)
print(roc_dat%>%filter(model=="GRE+GPA+RANK")%>%filter(TPR<0.57 & FPR<0.25)%>%
        summarise(threshold = min(probs),
                  FPR = max(FPR),
                  TPR = max(TPR)))
```

## Selecting a threshold

We can use many thresholds:

- We can optimize overall accuracy - this will be the inflection point in the curve
- We can set arbitrary thresholds (i.e. 10 percent false positive)

```{r}
roc_dat%>%filter(model=="GRE+GPA+RANK")%>%filter(FPR<0.1)%>%
        summarise(threshold = min(probs),
                  FPR = max(FPR),
                  TPR = max(TPR))
```

## Bonus points

- This model was fit to our observed data \pause
- Then predicted itself... \pause
- Can it predict new cases?

## Out of sample validation

- We could use this model to predict next year's admits to target high and low likelihood cases \pause
- But we only have one year of data. We can split our data into two sets: one for fitting the model (training) and one for evaluating the model fit (test data)

## Example with the admissions data

Let's fit the data to a 75 percent subset, then test it against the remaining 25 percent

```{r size = "tiny"}
sample_size<-trunc(nrow(admits) * 0.25)
test_rows<-sample(1:nrow(admits), sample_size, replace = FALSE)
training_dat<-admits[-test_rows,]
test_dat<-admits[test_rows,]
model_validation<-glm(admit~ gre + gpa + rank, 
                      data = admits,
                      family = "binomial")
yhat<-predict(model_validation, 
              newdata = test_dat,
              type = "response")
```

## Now check out the ROC curve

```{r echo = FALSE}
roc_validation<-simple_roc(labels = test_dat$admit,
             scores = yhat)

ggplot(roc_validation,
       aes(x=FPR, y = TPR))+ 
  geom_line() + 
  geom_abline(slope = 1, lty = 2)
```

## Out of sample validation is crucial for prediction

- Using the same data to train and test a model leads to overfitting
- New data is necessary to effectively check the performance of your model
- Especially in real world settings where mistakes can be dangerous/costly
