---
title: "Measurement error and missing data"
author: "Frank Edwards"
date: "5/1/2020"
output: binb::metropolis
---

```{r setup, include=FALSE}
library(MASS)
library(rethinking)
library(gridExtra)
library(tidyverse)
library(gapminder)
library(brms)
library(broom)
set.seed(1)
select<-dplyr::select

knitr::opts_chunk$set(tidy = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

## What is measurement error?

- When randomly sampling a unit from a larger population, we obtain a single value
- This single value $x$ differs by an unknown amount from the true population value, $\mu$. This is called sampling error.
- This means that our observation is but one of many possible values that could have been observed with a random sample of the population
- Treating the observation as the **truth** is thus unwise

## Divorce data again, now with measurement error!

```{r}
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce

head(d %>% select(Location, Divorce, Divorce.SE))
```

## Visualizing the uncertainty

```{r, size = "tiny", fig.height = 5}
ggplot(d, aes(x = reorder(Location, Divorce), y = Divorce, 
       ymin = Divorce - Divorce.SE * 1.65, ymax = Divorce + Divorce.SE * 1.65)) + 
  coord_flip() + 
  geom_pointrange(size = 0.1) + 
  labs(x = "State")
```

## Error is a function of population size

The American Community Survey (ACS) samples a fixed percent of the population. Places with smaller populations have fewer sampled households and larger error

```{r size = "tiny", fig.height = 3}
ggplot(d, aes(x = Population, y = Divorce.SE)) + 
  geom_point()
```

## What this means in practice

```{r}
NJ<-d %>% filter(Loc=="NJ") %>% select(Loc, Divorce, Divorce.SE)
NJ
```

Let's assume that NJ's true Divorce rate is in fact 6.1 (we got very luck in sampling!). Here's ten possible values we *could* have obtained instead of 6.1

```{r size = "tiny"}
rnorm(10, 6.1, 0.46)
```

## What this means in practice

Let's say that the true divorce rate in NJ is 6.3, this is the density of possible observations with the one percent ACS sample. 

```{r size = "tiny", fig.height = 3}
samples<-rnorm(1e5, 6.3, 0.46)
plot(density(samples))
```

## Treating the truth as a parameter

For each observed value of a state's divorce rate based on a sample, $D_{\textrm{obs}_i}$, there is a true state divorce rate $D_{\textrm{true}_i}$. The observation is one draw from the true sampling distribution

\[D_{\textrm{obs}_i} \sim \textrm{Normal}(D_{\textrm{true}_i}, D_{\textrm{SE}_i})\]

We don't observe $D_{\textrm{true}}$, but can estimate a posterior for it from our model, and incorporate uncertainty in measurement across the model.

## Defining a model

- Note that we'll now be estimating uncertainty in divorce rates as we estimate our model of divorce rates!

\[D_{\textrm{obs}_i} \sim \textrm{Normal}(D_{\textrm{true}_i}, D_{\textrm{SE}_i})\]
\[D_{\textrm{true}_i} \sim \textrm{Normal}(\mu_i, \sigma)\]
\[\mu_i = \alpha + \beta_A A_i + \beta_M M_i\]
\[\alpha \sim \textrm{Normal}(0, 1)\]
\[\beta_A \sim \textrm{Normal}(0, 1)\]
\[\beta_M \sim \textrm{Normal}(0, 1)\]
\[\sigma \sim \textrm{Exponential}(1)\]

## Estimating the model

```{r size = "tiny", results = "hide", cache = T}
d_slim<-list(
  D_obs = scale(d$Divorce), A = scale(d$MedianAgeMarriage), 
  M = scale(d$Marriage), D_se = d$Divorce.SE / sd(d$Divorce),
  N = nrow(d))

m_error<-ulam(alist(
  D_obs ~ dnorm(D_true, D_se),
  vector[N]:D_true ~ dnorm(mu, sigma),
  mu<-a + bA * A + bM * M,
  a ~ dnorm(0, 0.2),
  bA ~ dnorm(0, 0.5),
  bM ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data=d_slim, cores = 4, chains = 4)
```

## Estimate a model with no measurement error adjustment for comparison

```{r size = "tiny", results = "hide", cache = T}
m_no_error<-ulam(alist(
  D_obs ~ dnorm(mu, sigma),
  mu<-a + bA * A + bM * M,
  a ~ dnorm(0, 0.2),
  bA ~ dnorm(0, 0.5),
  bM ~ dnorm(0, 0.5),
  sigma ~ dexp(1)
), data=d_slim, cores = 4, chains = 4)
```

## Visualize the results

```{r echo = F}
m_error_post<-link(m_error)
m_no_error_post<-link(m_no_error)
m_error_mu<-link(m_error, 
                 data = 
                   data.frame(A = seq(-2.5, 3, length.out=50),
                              M = 0))

m_no_error_mu<-link(m_no_error, 
                 data = 
                   data.frame(A = seq(-2.5, 3, length.out=50),
                              M = 0))

plot_dat<-data.frame(M = d_slim$M,
                     A = d_slim$A,
                     D_obs = d_slim$D_obs,
                     d_error_mn = apply(m_error_post, 2, mean),
                     d_no_error_mn = apply(m_no_error_post, 2, mean),
                     A_sim = seq(-2.5, 3, length.out=50),
                     mu_mn = apply(m_error_mu, 2, mean),
                     mu_lwr = apply(m_error_mu, 2, PI)[1,],
                     mu_upr = apply(m_error_mu, 2, PI)[2,],
                     mu2_mn = apply(m_no_error_mu, 2, mean),
                     mu2_lwr = apply(m_no_error_mu, 2, PI)[1,],
                     mu2_upr = apply(m_no_error_mu, 2, PI)[2,])

ggplot(plot_dat, 
       aes(x = A, y = d_error_mn)) + 
  geom_ribbon(aes(x = A_sim, y= mu_mn, ymin = mu_lwr, ymax = mu_upr), alpha = 0.2) + 
  geom_line(aes(x = A_sim, y = mu_mn)) + 
  coord_cartesian(xlim=c(-2.5, 3), ylim=c(-2, 2))
```

## Visualize the results: error model posterior mu

```{r echo = F}
ggplot(plot_dat, 
       aes(x = A, y = d_error_mn)) + 
  geom_point(alpha = 0.5) + 
  geom_ribbon(aes(x = A_sim, y= mu_mn, ymin = mu_lwr, ymax = mu_upr), alpha = 0.2) + 
  geom_line(aes(x = A_sim, y = mu_mn))  + 
  coord_cartesian(xlim=c(-2.5, 3), ylim=c(-2, 2))
```

## Visualize the results: observed data (blue)

```{r echo = F}
ggplot(plot_dat, 
       aes(x = A, y = d_error_mn)) + 
  geom_point(alpha = 0.5) + 
  geom_ribbon(aes(x = A_sim, y= mu_mn, ymin = mu_lwr, ymax = mu_upr), alpha = 0.2) + 
  geom_line(aes(x = A_sim, y = mu_mn))  + 
  coord_cartesian(xlim=c(-2.5, 3), ylim=c(-2, 2)) + 
  geom_point(aes(x = A, y = D_obs), alpha = 0.5, color = "blue") + 
  geom_segment(aes(x = A, xend = A, y = d_error_mn,
                   yend = D_obs), alpha = 0.5) 
```

## Visualize the results: model without error adjustment (red)

```{r echo = F}
ggplot(plot_dat, 
       aes(x = A, y = d_error_mn)) + 
  geom_point(alpha = 0.5) + 
  geom_point(aes(y = d_no_error_mn), color = "red", alpha = 0.5) + 
  
  geom_ribbon(aes(x = A_sim, y= mu_mn, ymin = mu_lwr, ymax = mu_upr), alpha = 0.2) + 
  geom_line(aes(x = A_sim, y = mu_mn)) + 
  coord_cartesian(xlim=c(-2.5, 3), ylim=c(-2, 2))  +
  geom_point(aes(x = A, y = D_obs), alpha = 0.5, color = "blue") + 
  geom_segment(aes(x = A, xend = A, y = d_error_mn,
                   yend = D_obs), alpha = 0.5) 
```


## Visualize the results: magnitude of shrinkage

```{r echo = F}
plot_dat<-data.frame(D_se = d$Divorce.SE, D_obs = d_slim$D_obs,
                     post_mu = apply(m_error_post, 2, mean),
                     Population = d$Population)

ggplot(plot_dat, aes(x =D_se, y = post_mu - D_obs)) + 
  geom_point() + 
  geom_hline(yintercept = 0, lty = 2)
```

## The posterior for each observation of D

```{r echo = F}
post<-extract.samples(m_error)
post_D<-apply(post[["D_true"]], 2, PI)
plot_dat<-data.frame(post_dmin = post_D[1,],
                     post_dmax = post_D[2,],
                     D_obs = d_slim$D_obs,
                     D_se = d_slim$D_se,
                     State = d$Loc)

ggplot(plot_dat, 
       aes(x = reorder(State, D_obs), 
           ymin = post_dmin, 
           ymax = post_dmax)) + 
  coord_flip() + 
  geom_linerange(alpha = 0.5) + 
  geom_point(aes(y = D_obs)) + 
  labs(x = "State", y = "Divorce rate")
```

## Fitting this model with brms

```{r cache = T, results = "hide", size = "tiny"}
m_error_brm<-brm(D_obs|mi(D_se) ~ A + M,
                 prior = c(
                   prior(normal(0, 0.2), class = Intercept),
                   prior(normal(0, 0.5), class = b),
                   prior(exponential(1), class = sigma)),
                 data = d_slim, save_mevars = T)
```

## Visualzing the brms inferences
```{r echo = F}
post<-data.frame(posterior_interval(m_error_brm)) %>% 
  slice(5:54) %>% 
  mutate(State = d$Loc,
         D_obs = d_slim$D_obs)

ggplot(post, aes(x = reorder(State, D_obs), y = D_obs,
                 ymin = X2.5., ymax = X97.5.)) + 
  geom_point() + 
  geom_linerange() + 
  coord_flip()
```

# Measurement error on both outcomes and predictors

## Let's look at that data again

```{r}
head(d %>% 
       select(Loc, Marriage, Marriage.SE, 
              Divorce, Divorce.SE))
```

## What this means in practice

If we assume that the observed marriage and divorce values are the true value, the sampling distributions look like this

```{r echo = F, fig.height = 4 }
out<-list()
for(i in 1:nrow(d)){
  temp<-d[i,]
  out[[i]]<-data.frame(State = temp$Loc,
                       Marriage = rnorm(1000, temp$Marriage, 
                                        temp$Marriage.SE),
                       Divorce = rnorm(1000, temp$Divorce,
                                       temp$Divorce.SE))
}
plot_dat<-bind_rows(out)

ggplot(plot_dat, aes(x = Marriage, y = Divorce)) +
  geom_density2d() + 
  facet_wrap(~State, ncol = 10)
```

## Incorporating two kinds of measurement error into our model

\[D_{\textrm{obs}_i} \sim \textrm{Normal}(D_{\textrm{true}_i}, D_{\textrm{SE}_i})\]
\[D_{\textrm{true}_i} \sim \textrm{Normal}(\mu_i, \sigma)\]
\[\mu_i = \alpha + \beta_A A_i + \beta_M M_{\textrm{true}_i}\]
\[M_{\textrm{obs}_i} \sim \textrm{Normal}(M_{\textrm{true}_i}, M_{SE_i})\]
\[M_{\textrm{true}_i} \sim \textrm{Normal}(0,1)\]
\[\alpha \sim \textrm{Normal}(0, 1)\]
\[\beta_A \sim \textrm{Normal}(0, 1)\]
\[\beta_M \sim \textrm{Normal}(0, 1)\]
\[\sigma \sim \textrm{Exponential}(1)\]

## Estimating the model with ulam()

```{r cache = T, results = "hide"}
d_slim$M_se<-d$Marriage.SE/sd(d$Marriage)
m_error_both<-ulam(alist(
  D_obs ~ dnorm(D_true, D_se),
  vector[N]:D_true ~ dnorm(mu, sigma),
  mu<-a + bA * A + bM * M,
  M ~ dnorm(M_true, M_se),
  vector[N]:M_true ~ dnorm(0,1),
  a ~ dnorm(0, 0.2),
  bA ~ dnorm(0, 0.5),
  bM ~ dnorm(0, 0.5),
  sigma ~ dexp(1)), 
  data=d_slim, cores = 4, chains = 4)
```

## Estimating the model with brm()

```{r cache = T, results = "hide"}
m_error_brm_both<-brm(D_obs|mi(D_se) ~ A + 
                        me(M, M_se),
                 prior = c(
                   prior(normal(0, 0.2), class = Intercept),
                   prior(normal(0, 0.5), class = b),
                   prior(exponential(1), class = sigma)),
                 data = d_slim, save_mevars = T)

```

## Measurement error

- Data are often measured with error
- Sometimes we know this error - that's great!
- Incorporate the measurement error into your model
- Bayesian models are generative: we can estimate a posterior for variables measured with error at the same time as we estimate other parameters
- Correlated errors across multiple measures can induce bias (see DAGs on page 498)

# Missing data

## Missing data

- Somtimes variables are missing a value \pause
- R calls these `NA`\pause
- There can be many reasons that a value isn't reported\pause
- Think hard about why it may have happened\pause
- Software typically defaults to *listwise deletion*, or *complete case analysis* \pause
- At best, this discards perfectly good information in the other variables in that row. At worst, it leads to biased inference.

## Imputation

- Avoid discarding data whenever possible \pause
- Use common sense to replace missings when possible (e.g. in panel data when we have a respondent's age in one wave but not another) \pause
- Avoid imputing data with a single value when we are uncertain (never replace a missing with a mean or interpolation). This overstates your certainty, and artificially narrows posterior intervals \pause
- Use imputation models to populate your uncertainty into the analysis.

## Missing data typology

The ludicrous names that get used in the literature to describe various mechanisms for missing data

- Missing completely at random: each observation has equal probability of being missing.
- Missing at random: each observation's probability of being missing is conditional on some set of measured variables
- Missing not at random: each observation's probaility of being missing is conditional on some set of unmeasured variables

## This dog ate my homework

He's still a good boy

\begin{figure}
  \includegraphics[width=\linewidth]{basil.jpg}
\end{figure}

## Why do dogs make homework go missing?

Let's asssume that $H$ is the grade a homework would have received if graded, $S$ is how much a student studied, and $D$ is whether a dog ate the homework. We observe $H_obs$, a vector of grades where some are missing.

## Dogs eat homework completely at random

Nothing affects a dog's decision to eat homework, they just strike at random!

```{r, echo = F, fig.width = 4, fig.align='center', fig.height = 2}
library(dagitty)

MAR<-dagitty("dag{
             S->H
             H->H_obs
             D->H_obs
             H[unobserved]
             }")
coordinates(MAR)<-list(x=c(S=0, D=0, H=1, H_obs=1),
                       y = c(S=0, H_obs = 1, H=0, D = 1))
drawdag(MAR)
```

## Simulate random homework eating

Dogs eat homework 20 percent of the time, and strike at random

```{r size = "tiny"}
N<-100
S<-rnorm(N)
H<-rbinom(N, size = 10, prob = inv_logit(S))
D<-rbinom(N, 1, p = 0.2)
H_obs<-H
H_obs[D==1]<-NA
summary(H_obs)
```

## How does the missingness affect inference? List-wise deletion

```{r size = "tiny", cache = T, results = "hide"}
library(broom)
d<-data.frame(H_obs = H_obs, S = S) %>% filter(!is.na(H_obs))
mcar_0<-brm(H_obs ~ S, data = d)
```

```{r}
tidy(mcar_0)
```


## How does the missingness affect inference? Complete data

```{r size = "tiny", cache = T, results = "hide"}
d<-data.frame(H = H, S = S) 
mcar_1<-brm(H ~ S, data = d)
```

```{r}
tidy(mcar_1)
```

## Dogs eat homework when students study too much

Why don't you want to go play?

```{r, echo = F, fig.width = 4, fig.align='center', fig.height = 2}
MAR<-dagitty("dag{
             S->H
             S->D
             H->H_obs
             D->H_obs
             H[unobserved]
             }")
coordinates(MAR)<-list(x=c(S=0, D=0, H=1, H_obs=1),
                       y = c(S=0, H_obs = 1, H=0, D = 1))
drawdag(MAR)
```

## Simulate bad dogs

```{r}
P<-ifelse(S>0, 0.5, 0)
D<-rbinom(N, 1, p = P)
H_obs<-H
H_obs[D==1]<-NA
summary(H_obs)
```

## How does the missingness affect inference? List-wise deletion

```{r, size = "tiny", cache = T, results = "hide"}
d<-data.frame(H_obs = H_obs, S = S) %>% filter(!is.na(H_obs))
mar_0<-brm(H_obs ~ S, data = d)
```

```{r}
tidy(mar_0)
```


## How does the missingness affect inference? Complete data

```{r size = "tiny", cache = T, results = "hide"}
d<-data.frame(H = H, S = S) 
mar_1<-brm(H ~ S, data = d)
```

```{r}
tidy(mar_1)
```


## Dogs hate noise, and so does homework

Noisy homes $X$ make bad homework and dogs

```{r, echo = F, fig.width = 4, fig.align='center', fig.height = 2}
MAR<-dagitty("dag{
             S->H
             S->D
             X -> H
             X->D
             H->H_obs
             D->H_obs
             H[unobserved]
             X[unobserved]
             }")
coordinates(MAR)<-list(x=c(S=0, D=0, H=2, H_obs=2, X = 1),
                       y = c(S=0, H_obs = 2, H=0, D = 2, X = 1))
drawdag(MAR)
```

## Simulate noisy houses

```{r}
N<-100
S<-rnorm(N)
X<-rnorm(N)
H<-rbinom(N, size = 10, prob = inv_logit(2 + S - 2*X))
D<-ifelse(X>1, 1, 0)
H_obs<-H
H_obs[D==1]<-NA
summary(H_obs)
```

## How does the missingness affect inference? List-wise deletion

```{r, size = "tiny", cache = T, results = "hide"}
d<-data.frame(H_obs = H_obs, S = S, X = X) %>% filter(!is.na(H_obs))
mnar_0<-brm(H_obs ~ S, data = d)
```

```{r}
tidy(mnar_0)
```


## How does the missingness affect inference? Complete data

```{r size = "tiny", cache = T, results = "hide"}
d<-data.frame(H = H, S = S) 
mnar_1<-brm(H ~ S, data = d)
```

```{r}
tidy(mnar_1)
```


## How does the missingness affect inference? Complete data with unobserved cause

```{r size = "tiny", cache = T, results = "hide"}
d<-data.frame(H = H, S = S, X = X) 
mnar_2<-brm(H ~ S + X, data = d)
```

```{r}
tidy(mnar_2)
```

## Very good dogs

Dogs only eat bad homework

```{r, echo = F, fig.width = 4, fig.align='center', fig.height = 2}
MAR<-dagitty("dag{
             S->H
             H->D
             H->H_obs
             D->H_obs
             H[unobserved]
             }")
coordinates(MAR)<-list(x=c(S=0, D=0, H=2, H_obs=2),
                       y = c(S=0, H_obs = 2, H=0, D = 2))
drawdag(MAR)
```

## Simulate good dogs

```{r}
N<-100
S<-rnorm(N)
H<-rbinom(N, size = 10, prob = inv_logit(S))
D<-ifelse(H<5, 1, 0)
H_obs<-H
H_obs[D==1]<-NA
summary(H_obs)
```

## How does the missingness affect inference? List-wise deletion

```{r, size = "tiny", cache = T, results = "hide"}
d<-data.frame(H_obs = H_obs, S = S) %>% filter(!is.na(H_obs))
mnar_0<-brm(H_obs ~ S, data = d)

```

```{r}
tidy(mnar_0)
```

## How does the missingness affect inference? Complete data

```{r size = "tiny", cache = T, results = "hide"}
d<-data.frame(H = H, S = S) 
mnar_1<-brm(H ~ S, data = d)
```

```{r}
tidy(mnar_1)
```

## Bayesian imputation

- Much like with measurement error, we can treat missing values as parameters to be estimated from our model.
- HMC samples continuous missing measures well
- But it can't handle categorical measures as easily (see 15.3 for a method)
- We're going to use brm(), but see 15.2.2 for examples using ulam()

## Bayesian imputation with brm()

```{r}
library(mice)
data(nhanes)
summary(nhanes)
```

## Let's build a model to predict BMI as a function of age and cholesterol

```{r results = "hide"}
m0<-brm(bmi ~ age + chl, 
        data = nhanes, cores = 4)
```

```{r}
tidy(m0)
```

## This model dropped the missing values in bmi and chl

- We can impute values by sampling them with HMC, giving them a likelihood and priors
- We'll obtain posteriors for each missing value
- We specify these likelihoods and priors explicitly

```{r results = "hide", eval = F, cache = T}
m1 <- brm(bmi|mi() ~ age + chl, 
          data = nhanes)
```

## But we've got missingness on chl too

We need to specify a model with more than one likelihood, as we did in the measurement error model. We set (missing and non-missing) values in bmi to be a function of age and cholesterol, and missing cholesterol values to be a function of age.

```{r results = "hide", cache = T}
formula_2 <- 
  bf(bmi | mi() ~ age + mi(chl)) + # BMI model
  bf(chl | mi() ~ age) # chl model
m2 <- brm(formula_2,
          data = nhanes)
```

## The output

```{r size = "tiny"}
summary(m2)
```


## Visualizing the imputation

```{r fig.height = 4}
post<-posterior_samples(m2)
plot(density(post$`Ymi_bmi[10]`))
```

## Bayesian imputation: pros/cons

**Pros**
- We can allow for very complex structures in our models
- We can neatly specify variable specific models for missing data
- Sampling missing values using HMC as part of the model is consistent with Bayesian modeling principals

**Cons**
- Gets technically complex quickly
- Doesn't have easy solution for categorical data
- Computationally intensive for big data

## Multiple imputation by chained equations (MICE)

MICE is a common pseudo-Bayesian approach to missing data. It produces $k$ predictions for each unobserved variable based on a fully conditional regression models (where each variable is a function of all others).

- We'll allow each variable in the model to be a function of all others (we can relax this)
- Then make conditional predictions for each missing value
- This results in $k$ complete datasets
- We apply our analysis over each dataset, and pool results

For a detailed description of the method and software, See Van Buuren and  Groothuis-Oudshoorn, 2011: http://www.jstatsoft.org/v45/i03/paper

## MICE in practices

It's honestly too easy

```{r, size = "tiny", results = "hide"}
library(mice)
imp_nhanes<-mice(nhanes, m = 10, maxit = 20)
summary(imp_nhanes)
```

## Visualizing convergence

```{r}
plot(imp_nhanes)
```

## Visualizing the imputations

```{r}
stripplot(imp_nhanes, chl~.imp, pch=20, cex=2)
```

## Changing predictors

If we've got a collinear variable or a factor with many categories, we may want to exclude it from the model. Columns indicate predictors, row indicates outcomes.

```{r size = "tiny"}
pred<-imp_nhanes$predictorMatrix
```

Turn off hyp as a predictor of chl

```{r size = "tiny"}
pred["chl", "hyp"]<-0
pred
```

## Use the new predictor matrix

```{r size = "tiny", results = "hide"}
imp_nhanes2<-mice(nhanes, m = 10, maxit = 20,
                  predictorMatrix = pred)
summary(imp_nhanes)
```

## Change imputation methods

- The default in mice for continuous measures is partial mean matching
- The algorithm constructs a regression model, samples new coefficients from the parameter distribution, then makes a prediction. It then randomly selects one proximate observation from the observed data
- This makes the imputation data appear similar to the observed
- But sometimes we may not want to to do this, or may have categorical data

## Imputation methods

For a full list of methods, see https://stefvanbuuren.name/fimd/sec-modelform.html

```{r}
meth<-imp_nhanes$method
```

Let's change chl to a linear model

```{r}
meth[4]<-"norm"
```

And re-run the model

```{r size = "tiny", results = "hide"}
imp_nhanes3<-mice(nhanes, m = 10, maxit = 20,
                  method = meth)
summary(imp_nhanes3)
```

## Visualize imputations

```{r}
densityplot(imp_nhanes3)
```

## Using the imputed data

After imputation, we conduct our analysis over each imputed dataset. 

Typically, we'll need to separately fit each model. 

For frequentist methods, either use a loop or the with() function

```{r}
fit <- with(imp_nhanes3, lm(bmi ~ chl))
```

Then pool your results according to Rubin's rules for combination. This averages beta parameters, and adjusts standard errors for cross-imputation variance

## The results

```{r size = "tiny"}
pool(fit)
```

## With brms

In a Bayesian context, we don't have to worry about formulas for combination. We fit the model to each dataset, then pool the posterior samples from each for inference.

brms provides brm_multiple() to do this

```{r, cache = T, results = "hide", size = "tiny"}
brm_mi<-brm_multiple(bmi ~ age + chl, 
                     data =imp_nhanes3, cores = 4)
```

## Output

```{r size = "tiny"}
summary(brm_mi)
```

## The posterior samples

```{r}
post<-posterior_samples(brm_mi)
nrow(post)
```

## Summary

- Measurement error is an important part of the data generating process
- Ignoring it presumes we have perfect measurement, can bias inference, and understates uncertainty
- Missing data is also important. List-wise deletion at best discards information (and overstates certainty), at worst biases inference
- If data is missing completely at random, or is conditional on an observed variable, we can impute the missings and recover valid inference
- If missingness is correlated with the outcome, we've got a problem

## Further reading

- Further reading on mice: http://www.gerkovink.com/miceVignettes/
- Further reading on Bayesian imputation and brms: https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html

## Thank you!

Thanks for a wonderful semester and for being experimental subjects as I try teaching Bayes! 

Stay safe, and please be in touch: frank.edwards@rutgers.edu