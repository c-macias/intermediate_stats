---
title: "Lab: Easy mode"
author: "Frank Edwards"
date: "4/24/2020"
output: binb::metropolis
---

```{r setup, include=FALSE}
library(MASS)
library(rethinking)
library(gridExtra)
library(tidyverse)
library(gapminder)
set.seed(1)
select<-dplyr::select

knitr::opts_chunk$set(tidy = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
```

# GLMs

## Refresher: lm()

- We can fit a frequentist regression model with a normal likelihood (using OLS) with the lm() function. \pause
- R formulas take on an outcome ~ predictor1 + predictor2, data structure

```{r size = "tiny"}
library(broom)
data(WaffleDivorce)
m0<-lm(Divorce ~ Marriage, data = WaffleDivorce)
tidy(m0)
```

## Refresher: transformations and interactions

- We can use math functions like log(), exp() and sqrt() on outcomes or predictors
- To use other math, wrap a statement in I()

```{r size = "tiny"}
m1<-lm(log(Divorce) ~ sqrt(Marriage) + I(WaffleHouses / Population), data = WaffleDivorce)
tidy(m1)
m2<-lm(Divorce ~ Marriage * South, data = WaffleDivorce)
tidy(m2)
```

## The GLM function and model families

- We can estimate generalized linear models using glm()
- The family argument specifies the likelihood: family = "binomial", "gaussian", "Gamma", "poisson" are most common
- The canonical link function for each family is specified by default

```{r size = "tiny"}
admissions <- read_csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
head(admissions)
```

## Logistic regression

```{r}
m3<-glm(admit ~ gre + gpa + factor(rank), 
        data = admissions, 
        family = "binomial")
tidy(m3)
```

## Binomial count models

```{r}
data("UCBadmit")
head(UCBadmit)
```

## Binomial count models

```{r}
m4<-glm(cbind(admit, reject) ~ applicant.gender + 
          factor(dept), 
        data = UCBadmit, family = "binomial")
tidy(m4)
```

## Poisson models

```{r}
fe<-read_csv("./fe_demo.csv")
head(fe)
```

## Poisson models

```{r}
m5<-glm(deaths ~ race.ethn, 
        data = fe, family = "poisson")
tidy(m5)
```

## Poisson models with offset

```{r}
fe<-fe %>% 
  filter(pop>0)
m6<-glm(deaths ~ race.ethn,
        offset = log(pop), 
        data = fe, family = "poisson")
tidy(m6)
```

## Other models

- MASS::glm.nb() for negative binomial regression
- pscl::zeroinfl() for zero-inflated poisson regression
- nnet::multinom() for multinomial (categorical) regression

# Frequentist multilevel models

## the lme4 package

```{r}
library(lme4)
```

- lme4 syntax follows basic R formula syntax, but now adds variable intercept and slope terms
- basic format: outcome ~ predictors + (1|varying slope) + (varying slope | varying intercept), data = data

## Estimating a multilevel model: country intercepts

```{r size = "tiny"}
library(gapminder)
m7<-lmer(lifeExp ~ year + (1|country) + (1|continent), 
         data = gapminder)
tidy(m7)
```

## Estimating a multilevel model: country intercepts, nested within continent intercepts

```{r size = "tiny"}
m8<-lmer(lifeExp ~ year + (1|continent/country), 
         data = gapminder)
tidy(m8)
```

## Varying slopes, country and continent intercepts

```{r size = "tiny"}
m9<-lmer(lifeExp ~ year + (year|continent/country), 
         data = gapminder)
tidy(m9)
```

## GLMs and lme4, Poisson model with state intercepts

```{r size = "tiny"}
m10<-glmer(deaths ~ race.ethn + (1|state), 
           data = fe, family = "poisson")
tidy(m10)
```

## Add an offset

```{r size = "tiny"}
m11<-glmer(deaths ~ race.ethn + offset(log(pop)) +
             (1|state), 
           data = fe, family = "poisson")
tidy(m11)
```

## Add overdispersion

We can model overdispersion in counts with a variable intercept for each observation. This effectively creates an error term for a model that typically lacks one.

```{r}
fe<-fe %>% 
  mutate(obs_n = 1:nrow(fe))
```

## Add overdispersion

```{r size = "tiny"}
m12<-glmer(deaths ~ race.ethn + offset(log(pop)) +
             (1|state) + (1|obs_n), 
           data = fe, family = "poisson")
tidy(m12)
```

# Bayesian models with lme4 and glm syntax

## The brms package

- brms uses the core R and lme4 formula syntax, but uses rstan and HMC to fit models
- we can specify priors relatively easily
- For a full translation of Statistical Rethinking into brms, see this very detailed guide: https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/

## brms basics

```{r results = "hide"}
library(brms)
brm0<-brm(Divorce ~ Marriage, 
        data = WaffleDivorce,
        prior = c(prior(normal(0,2), class = Intercept),
                  prior(normal(0,2), class = b, coef = Marriage),
                  prior(exponential(1), class = sigma))
        )

ulam0<-ulam(alist(
  Divorce ~ dnorm(mu, sigma),
  mu <- alpha + beta * Marriage,
  alpha ~ dnorm(0,2),
  beta ~ dnorm(0,2),
  sigma ~ dexp(1)
  ), data = WaffleDivorce)

```

## Results

```{r, size = "tiny"}
summary(brm0)
```

## Traceplots and density plots

```{r size = "tiny", fig.height = 4}
## so easy!
plot(brm0)
```

## Directly sampling the posterior

```{r}
post<-posterior_samples(brm0)
head(post)
```

## Using the linear link function and new data

```{r size = "tiny", fig.height = 3}
sim_dat<-data.frame(Marriage = seq(1, 50, by = 0.1))
post_mu<-posterior_linpred(brm0, newdata = sim_dat)

sim_dat<-sim_dat %>% 
  mutate(mu_lwr = apply(post_mu, 2, function(x) quantile(x, 0.05)),
         mu_upr = apply(post_mu, 2, function(x) quantile(x, 0.95)),
         mu_mn = apply(post_mu, 2, mean))

ggplot(sim_dat, aes(x = Marriage, y = mu_mn)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = mu_lwr, ymax = mu_upr), alpha = 0.5)
```

## GLMs: logistic regression

```{r results = "hide", cache = T}
brm1<-brm(admit ~ gre + gpa,
          family = bernoulli,
          data = admissions,
          prior = c(prior(normal(0.5, 1), class = Intercept),
                    prior(normal(0, 1), class = b),
                    prior(normal(0,2), coef = "gre")
          ))
```

## Output

```{r size = "tiny"}
summary(brm1)
```

## Multilevel models

- brms is built to accept the syntax of lme4 - like formulas

```{r results = "hide", cache = T}
gapminder<-gapminder %>% 
  mutate(L_c = scale(lifeExp),
         year_c = ((year - min(year))/5))

brm7<-brm(L_c ~ year_c + (year_c|country), 
         data = gapminder, family = gaussian,
         prior = c(prior(normal(0, 5), class = Intercept),
                   prior(exponential(1), class = sigma),
                   prior(normal(0,2), class = b),
                   prior(lkj(2), class = cor)),
         iter = 4000, cores = 4)
```

## Output

```{r size = "tiny"}
summary(brm7)
```

## Check convergence

```{r, echo = F}
plot(brm7)
```

## Further reading

- An Introduction to Bayesian Multilevel Models Using brms: A Case Study of Gender Effects on Vowel Variability in Standard Indonesian https://osf.io/dpzcb/
- Fitting Linear Mixed-Effects Models Using lme4: https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
- brms: An R Package for Bayesian Multilevel Models using Stan: https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf
